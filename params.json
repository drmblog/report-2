{"name":"Assignment 2 - Lab Report","tagline":"#EURDRM2015","body":"# Introduction:\r\n\r\nEach year UEFA Champions League is trending across the web in news, blogs and user searches. This year is [no exception](https://www.google.com/trends/explore#q=%2Fm%2F0c1q0&cmpt=q&tz=Etc%2FGMT-1). For the purpose of this assignment I decided to look at discussions in Twitter medium related to one of the biggest annual football competition. More specifically I was interested in how users react to the Champions League and what is the trending mood of publications related to the topic. One of the most convenient ways to answer this question is to carry out sentiment analysis.\r\n\r\n---\r\n\r\n# Data Gathering and preprocessing\r\n\r\nIn order to retrieve data needed for the analysis several tools were used:\r\n- [Tableau software](http://www.tableau.com/), extended by [Twitter Web Data Connector](http://tableaujunkie.com/post/119681578798/creating-a-twitter-web-data-connector) \r\n- [Microsoft Office Excel](https://products.office.com/en-us/excel)\r\n- [ContText](http://wiki.contextgarden.net/Main_Page)\r\n\r\nTwitter Web Data Connector enables Tableau users to scrape most actual data from Twitter according to the indicated query. In this case, data was scraped using the *«Champions League»* term. After raw data was collected a *status text* dimension was loaded in the spreadsheet. Analysis of existing data however would not make sense, as raw results featured publications in different languages. For this reason new quick filter was created based on  the *language* dimension. Only *english language* checkbox was selected in the filter settings to get publications exclusively in english language.\r\n\r\n![Figure 1](https://github.com/drmblog/report-2/blob/master/images/Figure%201.png?raw=true)\r\n\r\nAfter that the data was exported to Excel spreadsheet using \r\n`Worksheet - export - crosstab to Excel` function in Tableau. The Excel environment was used to preprocess the data and get rid of unimportant characters. It was done by an integrated `clean` function. After all the modifications took place, corpus was saved as a new file with *.txt* extension. \r\n\r\nThe next step taken in data preprocessing chain was removal of *stop-words* from existing corpus. In order to achieve that, the corpus was loaded in ConText software and appropriate function was used: `Text analysis - Preprocessing -  Remove Stop Words`. The outputs of operation were saved to a new file. \r\n\r\n---\r\n\r\n# Data analysis and results\r\n\r\nThe analysis of corpus took place in the ConText software as well, with the implementation of `Text analysis - Summarization - Sentiment Analysis` function. \r\n\r\n![Figure 4](https://github.com/drmblog/report-2/blob/master/images/Figure4.png?raw=true)\r\n\r\nThe outcomes of an analysis that come in *.csv* file were loaded in Tableau software. In order for data to be properly analyzed and to be spread in separate columns, there was a need to use `split` function (activated as an option after right click on initial row in the spreadsheet). All the columns were renamed manually, according to the dimensions and values they represent, as software did not automate this process. \r\n\r\n![Figure5](https://github.com/drmblog/report-2/blob/master/images/Figure5.png?raw=true)\r\n\r\nFew transformations had to be made in order to know, what was the dominating sentiment in the data. As ConText software captures the term, its sentiment and its frequency - the *frequency dimension* had to be transformed into *measure*. This provided the possibility to see the *sum of frequency* for each of the sentiments and provide proper visual results. \r\n\r\nBased on those results it is possible to see that even though the amount of captured positive sentiments were bigger than negative ones, the count of sentiments frequency in the corpus reveals that totally it was more negative. \r\n\r\n![Figure 6](https://github.com/drmblog/report-2/blob/master/images/Figure6.png?raw=true)\r\n\r\n\r\nThe type of data captured also allowed to experiment with the *packed bubble* visualization for each term. The *sentiment dimension* was used as a quick filter to get different visualizations for negative and positive sentiments. \r\n\r\n![Figure 7](https://github.com/drmblog/report-2/blob/master/images/Figure7.png?raw=true)\r\n![Figure 8](https://github.com/drmblog/report-2/blob/master/images/Figure8.png?raw=true)\r\n\r\nEven though the research question was already answered another part of corpus analysis was executed. The final step concentrated on topic modeling. This was done with the help of ConText software and its integrated function: `Text analysis - Summarisation - Topic Modelling`. The *number of topics* was set to 10. The same counter was applied to the *number of words per topic* field. The *number of iterations* was set to 700. \r\n\r\nThe result of topic modeling were not good enough and required additional cycles of *stop-word* removal process. This was obvious as some of the topics featured irrelevant information, for example parts of an interactive links such as \"https\".\r\n\r\n---\r\n\r\n# Conclusion\r\n\r\nThe workflow between Tableau and ConText software is pretty straightforward, however requires some additional modifications of data. Moreover, if researches want to move further than sentiments analysis a more complex approach has to be applied to data and more attention has to be devoted to preprocessing part. \r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}